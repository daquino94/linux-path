{
  "id": 14,
  "title": "अद्वितीय (Unique)",
  "lessonContent": "अद्वितीय (अद्वितीय) कमांड पाठ को पार्स करने के लिए एक और उपयोगी उपकरण है।\n\nमान लीजिए आपके पास एक फ़ाइल है जिसमें कई डुप्लिकेट हैं:\n\n<pre>\nreading.txt\nbook\nbook\npaper\npaper\narticle\narticle\nmagazine\n</pre>\n\nऔर आप डुप्लिकेट को हटाना चाहते हैं, तो आप अद्वितीय कमांड का उपयोग कर सकते हैं:\n\n<pre>$ uniq reading.txt\nbook\npaper\narticle\nmagazine</pre>\n\nचलिए देखते हैं कि कितनी बार किस पंक्ति का होने का गणना करते हैं:\n\n<pre>$ uniq -c reading.txt\n2 book\n2 paper\n2 article\n1 magazine</pre>\n\nकेवल अद्वितीय मान प्राप्त करें:\n\n<pre>$ uniq -u reading.txt\nmagazine</pre>\n\nकेवल डुप्लिकेट मान प्राप्त करें:\n\n<pre>$ uniq -d reading.txt\nbook\npaper\narticle\n</pre>\n\n<b>नोट</b> : अद्वितीय डुप्लिकेट पंक्तियों का पता नहीं लगाता है जब तक वे आसपास न हों। उदाहरण के लिए:\n\nमान लीजिए आपके पास एक फ़ाइल है जिसमें डुप्लिकेट हैं जो आसपास नहीं हैं:\n\n<pre>\nreading.txt\nbook\npaper\nbook\npaper\narticle\nmagazine\narticle\n</pre>\n\n<pre>$ uniq reading.txt\nreading.txt\nbook\npaper\nbook\npaper\narticle\nmagazine\narticle</pre>\n\nअद्वितीय द्वारा वापसी किया गया परिणाम सभी प्रविष्टियों को शामिल करेगा जैसा कि पहले उदाहरण में था।\n\nअद्वितीय की इस सीमा को पार करने के लिए हम अद्वितीय के साथ सॉर्ट का उपयोग कर सकते हैं:\n\n<pre>\n$ sort reading.txt | uniq\narticle\nbook\nmagazine\npaper</pre>",
  "exercise": "यदि आप uniq -uc का प्रयास करते हैं तो आप क्या परिणाम प्राप्त करेंगे?",
  "quizQuestion": "फ़ाइल में डुप्लिकेट हटाने के लिए आप कौन सी कमांड का उपयोग करेंगे?",
  "quizAnswer": "uniq",
  "slug": "अद्वितीयअद्वितीयकमांड"
}