{
  "id": 14,
  "title": "uniq (Unique)",
  "lessonContent": "The uniq (unique) command is another useful tool for parsing text.\n\nLet's say you had a file with lots of duplicates:\n\n<pre>\nreading.txt\nbook\nbook\npaper\npaper\narticle\narticle\nmagazine\n</pre>\n\nAnd you wanted to remove the duplicates, well you can use the uniq command:\n\n<pre>$ uniq reading.txt\nbook\npaper\narticle\nmagazine</pre>\n\nLet's get the count of how many occurrences of a line:\n\n<pre>$ uniq -c reading.txt\n2 book\n2 paper\n2 article\n1 magazine</pre>\n\nLet's just get unique values:\n\n<pre>$ uniq -u reading.txt\nmagazine</pre>\n\nLet's just get duplicate values:\n\n<pre>$ uniq -d reading.txt\nbook\npaper\narticle\n</pre>\n\n<b>Note</b> : uniq does not detect duplicate lines unless they are adjacent. For eg:\n\nLet's say you had a file with duplicates which are not adjacent:\n\n<pre>\nreading.txt\nbook\npaper\nbook\npaper\narticle\nmagazine\narticle\n</pre>\n\n<pre>$ uniq reading.txt\nreading.txt\nbook\npaper\nbook\npaper\narticle\nmagazine\narticle</pre>\n\nThe result returned by uniq will contain all the entries unlike the very first\nexample.\n\nTo overcome this limitation of uniq we can use sort in combination with uniq:\n\n<pre>\n$ sort reading.txt | uniq\narticle\nbook\nmagazine\npaper</pre>",
  "exercise": "What result would you get if you tried uniq -uc?",
  "quizQuestion": "What command would you use to remove duplicates in a file?",
  "quizAnswer": "uniq",
  "slug": "uniquniquecommand"
}
